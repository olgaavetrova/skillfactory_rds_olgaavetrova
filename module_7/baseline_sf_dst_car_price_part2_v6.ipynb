{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "baseline-sf-dst-car-price-part2-v6.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <center> Прогнозирование стоимости автомобиля <br> по его характеристикам, описанию и фотографии (Часть 2)"
      ],
      "metadata": {
        "id": "iWSmg5-kfMwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <img src=\"https://whatcar.vn/media/2018/09/car-lot-940x470.jpg\"/>"
      ],
      "metadata": {
        "id": "NC3TBUKnfQGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Необходимо создать модель, которая будет предсказывать стоимость автомобиля с пробегом в Москве по его характеристикам. Модель должна максимально быстро находить выгодные предложения."
      ],
      "metadata": {
        "id": "CE6skkX4gPmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module"
      ],
      "metadata": {
        "id": "m1YMXBCwjEy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow==2.3"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-02-18T11:45:04.243047Z",
          "iopub.execute_input": "2022-02-18T11:45:04.243571Z",
          "iopub.status.idle": "2022-02-18T11:45:12.507829Z",
          "shell.execute_reply.started": "2022-02-18T11:45:04.243531Z",
          "shell.execute_reply": "2022-02-18T11:45:12.506757Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wypuTg6ydvOW",
        "outputId": "e5864dda-a4cb-4799-9003-2dc9a07124f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 320.4 MB 46 kB/s \n",
            "\u001b[K     |████████████████████████████████| 459 kB 57.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 49.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.3 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations -q"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22z_eTPndvOX",
        "outputId": "935b7025-b3ba-47cb-84d4-a2565b7632e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 61 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 92 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 112 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 122 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 143 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 153 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 174 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 184 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 204 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 215 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 225 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 235 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 245 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 256 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 266 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 286 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 307 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 327 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 337 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 348 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 358 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 368 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 378 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 389 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 399 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 409 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 419 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 430 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 440 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 450 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 460 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 471 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 481 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 491 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 501 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 512 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 522 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 532 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 542 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 552 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 563 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 573 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 583 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 593 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 604 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 614 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 624 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 631 kB 11.0 MB/s \n",
            "\u001b[?25h  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TwyLuxTlZnY",
        "outputId": "cdc6e89a-7485-4d9f-cdb5-be47e3ac118a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.4-cp37-none-manylinux1_x86_64.whl (76.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.1 MB 62 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import PIL\n",
        "import cv2\n",
        "import re\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# keras\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import albumentations\n",
        "\n",
        "# plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#увеличим дефолтный размер графиков\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 10, 5\n",
        "#графики в svg выглядят более четкими\n",
        "%config InlineBackend.figure_format = 'svg' \n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "id": "6z7B3tWMdvOY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Python       :', sys.version.split('\\n')[0])\n",
        "print('Numpy        :', np.__version__)\n",
        "print('Tensorflow   :', tf.__version__)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njGN-UwYdvOZ",
        "outputId": "bc7a3246-b464-4a92-bb6e-e2adc8cee144"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python       : 3.7.12 (default, Jan 15 2022, 18:48:18) \n",
            "Numpy        : 1.21.5\n",
            "Tensorflow   : 2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "fNM3PmF1lvfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mape(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_pred-y_true)/y_true))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "rDPaQXo_dvOZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# фиксируем RANDOM_SEED, чтобы эксперименты были воспроизводимы\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "m6jo0JvpdvOa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "pGSucaEzdvOa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA"
      ],
      "metadata": {
        "id": "v_rz4CRzdvOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортируем данные с соревнования\n",
        "\n",
        "# Вариант 1 (Загружаем данные с Google Colab)\n",
        "drive.mount('/input/')\n",
        "DATA_DIR = '../input/MyDrive/Colab Notebooks/car-price-part2/'\n",
        "train = pd.read_csv(DATA_DIR + 'train.csv')\n",
        "test = pd.read_csv(DATA_DIR + 'test.csv')\n",
        "sample_submission = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
        "\n",
        "# Вариант 2 (Загружаем данные с соревнования Kaggle)\n",
        "# DATA_DIR = '../input/sf-dst-car-price-prediction-part2/'\n",
        "# train = pd.read_csv(DATA_DIR + 'train.csv')\n",
        "# test = pd.read_csv(DATA_DIR + 'test.csv')\n",
        "# sample_submission = pd.read_csv(DATA_DIR + 'sample_submission.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_9PchteOLXg",
        "outputId": "5d49abf5-cdc8-476a-844c-b5ae8225e906"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /input/; to attempt to forcibly remount, call drive.mount(\"/input/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на данные:\n",
        "\n",
        "| Наименование столбца | Значение столбца |\n",
        "| :--------- |:---------------------|\n",
        "| bodyType | Кузов |\n",
        "| brand | Бренд |\n",
        "| color | Цвет |\n",
        "| description | Комментарий продавца |\n",
        "| engineDisplacement | Объем двигателя |\n",
        "| enginePower | Мощность двигателя |\n",
        "| fuelType | Тип топлива |\n",
        "| mileage | Пробег, км |\n",
        "| modelDate | Дата модели |\n",
        "| model_info | Информация о модели? ? |\n",
        "| name | Наименование ? |\n",
        "| numberOfDoors | Количество дверей |\n",
        "| price | Цена |\n",
        "| productionDate | Год выпуска |\n",
        "| sell_id | Идентификатор объявления |\n",
        "| vehicleConfiguration | Конфигурация автомобиля |\n",
        "| vehicleTransmission | Коробка передач |\n",
        "| Владельцы | Количество владельцев |\n",
        "| Владение | Срок владения автомобилем |\n",
        "| ПТС | Наличие ПТС |\n",
        "| Привод | Привод автомобиля |\n",
        "| Руль | Расположение руля |"
      ],
      "metadata": {
        "id": "1CpBXw3c0yKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "BXadNbOwdvOc",
        "outputId": "77932ec6-ea49-4ff8-83ac-90e6bf8160d3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-52d33e33-7ce9-49ed-ae9c-0dbc78121786\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bodyType</th>\n",
              "      <th>brand</th>\n",
              "      <th>color</th>\n",
              "      <th>description</th>\n",
              "      <th>engineDisplacement</th>\n",
              "      <th>enginePower</th>\n",
              "      <th>fuelType</th>\n",
              "      <th>mileage</th>\n",
              "      <th>modelDate</th>\n",
              "      <th>model_info</th>\n",
              "      <th>name</th>\n",
              "      <th>numberOfDoors</th>\n",
              "      <th>price</th>\n",
              "      <th>productionDate</th>\n",
              "      <th>sell_id</th>\n",
              "      <th>vehicleConfiguration</th>\n",
              "      <th>vehicleTransmission</th>\n",
              "      <th>Владельцы</th>\n",
              "      <th>Владение</th>\n",
              "      <th>ПТС</th>\n",
              "      <th>Привод</th>\n",
              "      <th>Руль</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>седан</td>\n",
              "      <td>BMW</td>\n",
              "      <td>чёрный</td>\n",
              "      <td>Авто на бодром ходу.  Все работает отлично.  П...</td>\n",
              "      <td>3.0 LTR</td>\n",
              "      <td>272 N12</td>\n",
              "      <td>бензин</td>\n",
              "      <td>245000</td>\n",
              "      <td>2007</td>\n",
              "      <td>5ER</td>\n",
              "      <td>530xi 3.0 AT (272 л.с.) 4WD</td>\n",
              "      <td>4</td>\n",
              "      <td>599000.0</td>\n",
              "      <td>2007</td>\n",
              "      <td>1099980990</td>\n",
              "      <td>SEDAN AUTOMATIC 3.0</td>\n",
              "      <td>автоматическая</td>\n",
              "      <td>3 или более</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Оригинал</td>\n",
              "      <td>полный</td>\n",
              "      <td>Левый</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>седан</td>\n",
              "      <td>AUDI</td>\n",
              "      <td>серебристый</td>\n",
              "      <td>Продажа от собственника, второй владелец, ПТС ...</td>\n",
              "      <td>2.8 LTR</td>\n",
              "      <td>204 N12</td>\n",
              "      <td>бензин</td>\n",
              "      <td>183000</td>\n",
              "      <td>2011</td>\n",
              "      <td>A6</td>\n",
              "      <td>2.8 CVT (204 л.с.)</td>\n",
              "      <td>4</td>\n",
              "      <td>850000.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>1095836906</td>\n",
              "      <td>SEDAN VARIATOR 2.8</td>\n",
              "      <td>вариатор</td>\n",
              "      <td>2 владельца</td>\n",
              "      <td>8 лет и 6 месяцев</td>\n",
              "      <td>Оригинал</td>\n",
              "      <td>передний</td>\n",
              "      <td>Левый</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>седан</td>\n",
              "      <td>MERCEDES</td>\n",
              "      <td>чёрный</td>\n",
              "      <td>Внимание! Только для клиентов AVILON Автомобил...</td>\n",
              "      <td>3.5 LTR</td>\n",
              "      <td>306 N12</td>\n",
              "      <td>бензин</td>\n",
              "      <td>122733</td>\n",
              "      <td>2009</td>\n",
              "      <td>E_KLASSE</td>\n",
              "      <td>350 3.5 AT (306 л.с.) 4WD</td>\n",
              "      <td>4</td>\n",
              "      <td>1325000.0</td>\n",
              "      <td>2013</td>\n",
              "      <td>1100195530</td>\n",
              "      <td>SEDAN AUTOMATIC 3.5</td>\n",
              "      <td>автоматическая</td>\n",
              "      <td>3 или более</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Оригинал</td>\n",
              "      <td>полный</td>\n",
              "      <td>Левый</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>седан</td>\n",
              "      <td>AUDI</td>\n",
              "      <td>белый</td>\n",
              "      <td>В комплекте зимние колёса. 27.07.2020 Замена п...</td>\n",
              "      <td>2.0 LTR</td>\n",
              "      <td>180 N12</td>\n",
              "      <td>бензин</td>\n",
              "      <td>151000</td>\n",
              "      <td>2011</td>\n",
              "      <td>A6</td>\n",
              "      <td>2.0 CVT (180 л.с.)</td>\n",
              "      <td>4</td>\n",
              "      <td>815000.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>1099880662</td>\n",
              "      <td>SEDAN VARIATOR 2.0</td>\n",
              "      <td>вариатор</td>\n",
              "      <td>3 или более</td>\n",
              "      <td>4 года и 9 месяцев</td>\n",
              "      <td>Оригинал</td>\n",
              "      <td>передний</td>\n",
              "      <td>Левый</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>лифтбек</td>\n",
              "      <td>AUDI</td>\n",
              "      <td>белый</td>\n",
              "      <td>Отличный авто, 2011 года выпуска, кроме передн...</td>\n",
              "      <td>1.8 LTR</td>\n",
              "      <td>160 N12</td>\n",
              "      <td>бензин</td>\n",
              "      <td>140000</td>\n",
              "      <td>2007</td>\n",
              "      <td>A5</td>\n",
              "      <td>1.8 CVT (160 л.с.)</td>\n",
              "      <td>5</td>\n",
              "      <td>810000.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>1083244610</td>\n",
              "      <td>LIFTBACK VARIATOR 1.8</td>\n",
              "      <td>вариатор</td>\n",
              "      <td>3 или более</td>\n",
              "      <td>2 года и 9 месяцев</td>\n",
              "      <td>Оригинал</td>\n",
              "      <td>передний</td>\n",
              "      <td>Левый</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52d33e33-7ce9-49ed-ae9c-0dbc78121786')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52d33e33-7ce9-49ed-ae9c-0dbc78121786 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52d33e33-7ce9-49ed-ae9c-0dbc78121786');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  bodyType     brand        color  ...       ПТС    Привод   Руль\n",
              "0    седан       BMW       чёрный  ...  Оригинал    полный  Левый\n",
              "1    седан      AUDI  серебристый  ...  Оригинал  передний  Левый\n",
              "2    седан  MERCEDES       чёрный  ...  Оригинал    полный  Левый\n",
              "3    седан      AUDI        белый  ...  Оригинал  передний  Левый\n",
              "4  лифтбек      AUDI        белый  ...  Оригинал  передний  Левый\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCwZZb21dvOc",
        "outputId": "aa1cf397-57be-4cd3-e796-0fb2a5d9ce38"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6682 entries, 0 to 6681\n",
            "Data columns (total 22 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   bodyType              6682 non-null   object \n",
            " 1   brand                 6682 non-null   object \n",
            " 2   color                 6682 non-null   object \n",
            " 3   description           6682 non-null   object \n",
            " 4   engineDisplacement    6682 non-null   object \n",
            " 5   enginePower           6682 non-null   object \n",
            " 6   fuelType              6682 non-null   object \n",
            " 7   mileage               6682 non-null   int64  \n",
            " 8   modelDate             6682 non-null   int64  \n",
            " 9   model_info            6682 non-null   object \n",
            " 10  name                  6682 non-null   object \n",
            " 11  numberOfDoors         6682 non-null   int64  \n",
            " 12  price                 6682 non-null   float64\n",
            " 13  productionDate        6682 non-null   int64  \n",
            " 14  sell_id               6682 non-null   int64  \n",
            " 15  vehicleConfiguration  6682 non-null   object \n",
            " 16  vehicleTransmission   6682 non-null   object \n",
            " 17  Владельцы             6681 non-null   object \n",
            " 18  Владение              2356 non-null   object \n",
            " 19  ПТС                   6682 non-null   object \n",
            " 20  Привод                6682 non-null   object \n",
            " 21  Руль                  6682 non-null   object \n",
            "dtypes: float64(1), int64(5), object(16)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.nunique()"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xvCDczGdvOc",
        "outputId": "6cd7d6a6-38e3-4b26-e1dc-118e86f24c81"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bodyType                  17\n",
              "brand                      3\n",
              "color                     16\n",
              "description             6147\n",
              "engineDisplacement        48\n",
              "enginePower              146\n",
              "fuelType                   4\n",
              "mileage                 2900\n",
              "modelDate                 41\n",
              "model_info               118\n",
              "name                     900\n",
              "numberOfDoors              4\n",
              "price                   1628\n",
              "productionDate            38\n",
              "sell_id                 6682\n",
              "vehicleConfiguration     288\n",
              "vehicleTransmission        4\n",
              "Владельцы                  3\n",
              "Владение                 173\n",
              "ПТС                        2\n",
              "Привод                     3\n",
              "Руль                       2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Посмотрим на типы признаков:\n",
        "\n",
        "* bodyType - категориальный\n",
        "* brand - категориальный\n",
        "* color - категориальный\n",
        "* description - текстовый\n",
        "* engineDisplacement - числовой, представленный как текст\n",
        "* enginePower - числовой, представленный как текст\n",
        "* fuelType - категориальный\n",
        "* mileage - числовой\n",
        "* modelDate - числовой\n",
        "* model_info - категориальный\n",
        "* name - категориальный, желательно сократить размерность\n",
        "* numberOfDoors - категориальный\n",
        "* price - числовой, целевой\n",
        "* productionDate - числовой\n",
        "* sell_id - изображение (файл доступен по адресу, основанному на sell_id)\n",
        "* vehicleConfiguration - не используется (комбинация других столбцов)\n",
        "* vehicleTransmission - категориальный\n",
        "* Владельцы - категориальный\n",
        "* Владение - числовой, представленный как текст\n",
        "* ПТС - категориальный\n",
        "* Привод - категориальный\n",
        "* Руль - категориальный"
      ],
      "metadata": {
        "id": "aN1ZK5ISdvOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1: Создадим \"наивную\" модель \n",
        "Эта модель будет предсказывать среднюю цену по модели и году выпуска. \n",
        "C ней будем сравнивать другие модели.\n",
        "\n"
      ],
      "metadata": {
        "id": "jJfIYio-dvOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split данных\n",
        "data_train, data_test = train_test_split(train, test_size=0.15, shuffle=True, random_state=RANDOM_SEED)"
      ],
      "metadata": {
        "trusted": true,
        "id": "FDg8x6-udvOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Наивная модель\n",
        "predicts = []\n",
        "for index, row in pd.DataFrame(data_test[['model_info', 'productionDate']]).iterrows():\n",
        "    query = f\"model_info == '{row[0]}' and productionDate == '{row[1]}'\"\n",
        "    predicts.append(data_train.query(query)['price'].median())\n",
        "\n",
        "# заполним не найденные совпадения\n",
        "predicts = pd.DataFrame(predicts)\n",
        "predicts = predicts.fillna(predicts.median())\n",
        "\n",
        "# округлим\n",
        "predicts = (predicts // 1000) * 1000\n",
        "\n",
        "#оцениваем точность\n",
        "print(f\"Точность наивной модели по метрике MAPE: {(mape(data_test['price'], predicts.values[:, 0]))*100:0.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "Dy2lT9v2dvOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "dXkVTBE9dvOd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проведем быстрый анализ данных для того, чтобы понимать, сможет ли с этими данными работать наш алгоритм."
      ],
      "metadata": {
        "id": "it2QW-4LdvOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим, как выглядят распределения числовых признаков:"
      ],
      "metadata": {
        "id": "I868lnUMdvOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#посмотрим, как выглядят распределения числовых признаков\n",
        "def visualize_distributions(titles_values_dict):\n",
        "  columns = min(3, len(titles_values_dict))\n",
        "  rows = (len(titles_values_dict) - 1) // columns + 1\n",
        "  fig = plt.figure(figsize = (columns * 6, rows * 4))\n",
        "  for i, (title, values) in enumerate(titles_values_dict.items()):\n",
        "    hist, bins = np.histogram(values, bins = 20)\n",
        "    ax = fig.add_subplot(rows, columns, i + 1)\n",
        "    ax.bar(bins[:-1], hist, width = (bins[1] - bins[0]) * 0.7)\n",
        "    ax.set_title(title)\n",
        "  plt.show()\n",
        "\n",
        "visualize_distributions({\n",
        "    'mileage': train['mileage'].dropna(),\n",
        "    'modelDate': train['modelDate'].dropna(),\n",
        "    'productionDate': train['productionDate'].dropna()\n",
        "})"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "geUx17jldvOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итого:\n",
        "* CatBoost сможет работать с признаками и в таком виде, но для нейросети нужны нормированные данные."
      ],
      "metadata": {
        "id": "YTsrw-qgdvOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PreProc Tabular Data"
      ],
      "metadata": {
        "id": "DcZQMdSxdvOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#используем все текстовые признаки как категориальные без предобработки\n",
        "categorical_features = ['bodyType', 'brand', 'color', 'engineDisplacement', 'enginePower', 'fuelType', 'model_info', 'name',\n",
        "  'numberOfDoors', 'vehicleTransmission', 'Владельцы', 'Владение', 'ПТС', 'Привод', 'Руль']\n",
        "\n",
        "#используем все числовые признаки\n",
        "numerical_features = ['mileage', 'modelDate', 'productionDate']"
      ],
      "metadata": {
        "trusted": true,
        "id": "0jiQcaYGdvOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
        "train['sample'] = 1 # помечаем где у нас трейн\n",
        "test['sample'] = 0 # помечаем где у нас тест\n",
        "test['price'] = 0 # в тесте у нас нет значения price, мы его должны предсказать, поэтому пока просто заполняем нулями\n",
        "\n",
        "data = test.append(train, sort=False).reset_index(drop=True) # объединяем\n",
        "print(train.shape, test.shape, data.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "rm6Mww2advOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preproc_data(df_input):\n",
        "    '''includes several functions to pre-process the predictor data.'''\n",
        "    \n",
        "    df_output = df_input.copy()\n",
        "    \n",
        "    # ################### 1. Предобработка ############################################################## \n",
        "    # убираем не нужные для модели признаки\n",
        "    df_output.drop(['description','sell_id',], axis = 1, inplace=True)\n",
        "    \n",
        "    \n",
        "    # ################### Numerical Features ############################################################## \n",
        "    # Далее заполняем пропуски\n",
        "    for column in numerical_features:\n",
        "        df_output[column].fillna(df_output[column].median(), inplace=True)\n",
        "    # тут ваш код по обработке NAN\n",
        "    # ....\n",
        "    \n",
        "    # Нормализация данных\n",
        "    scaler = MinMaxScaler()\n",
        "    for column in numerical_features:\n",
        "        df_output[column] = scaler.fit_transform(df_output[[column]])[:,0]\n",
        "    \n",
        "    \n",
        "    \n",
        "    # ################### Categorical Features ############################################################## \n",
        "    # Label Encoding\n",
        "    for column in categorical_features:\n",
        "        df_output[column] = df_output[column].astype('category').cat.codes\n",
        "        \n",
        "    # One-Hot Encoding: в pandas есть готовая функция - get_dummies.\n",
        "    df_output = pd.get_dummies(df_output, columns=categorical_features, dummy_na=False)\n",
        "    # тут ваш код не Encoding фитчей\n",
        "    # ....\n",
        "    \n",
        "    \n",
        "    # ################### Feature Engineering ####################################################\n",
        "    # тут ваш код не генерацию новых фитчей\n",
        "    # ....\n",
        "    \n",
        "    \n",
        "    # ################### Clean #################################################### \n",
        "    # убираем признаки которые еще не успели обработать, \n",
        "    df_output.drop(['vehicleConfiguration'], axis = 1, inplace=True)\n",
        "    \n",
        "    return df_output"
      ],
      "metadata": {
        "trusted": true,
        "id": "VjbXI7FudvOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запускаем и проверяем, что получилось\n",
        "df_preproc = preproc_data(data)\n",
        "df_preproc.sample(10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "0PiNzsrMdvOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_preproc.info()"
      ],
      "metadata": {
        "trusted": true,
        "id": "1OK0mUz7dvOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data"
      ],
      "metadata": {
        "id": "2GODWLTGdvOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Теперь выделим тестовую часть\n",
        "train_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\n",
        "test_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n",
        "\n",
        "y = train_data.price.values     # наш таргет\n",
        "X = train_data.drop(['price'], axis=1)\n",
        "X_sub = test_data.drop(['price'], axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "9-Vsw7UGdvOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.info()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Fwkk4HzVdvOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: CatBoostRegressor"
      ],
      "metadata": {
        "id": "ZrYpZMZadvOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, shuffle=True, random_state=RANDOM_SEED)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Lysgg28mdvOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CatBoostRegressor(iterations = 5000,\n",
        "                          #depth=10,\n",
        "                          #learning_rate = 0.5,\n",
        "                          random_seed = RANDOM_SEED,\n",
        "                          eval_metric='MAPE',\n",
        "                          custom_metric=['RMSE', 'MAE'],\n",
        "                          od_wait=500,\n",
        "                          #task_type='GPU',\n",
        "                         )\n",
        "model.fit(X_train, y_train,\n",
        "         eval_set=(X_test, y_test),\n",
        "         verbose_eval=100,\n",
        "         use_best_model=True,\n",
        "         #plot=True\n",
        "         )"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "Ve8izr-ddvOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_catboost = model.predict(X_test)\n",
        "print(f\"TEST mape: {(mape(y_test, test_predict_catboost))*100:0.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "EvRDijB_dvOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submission"
      ],
      "metadata": {
        "id": "YeQVoqsbdvOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_predict_catboost = model.predict(X_sub)\n",
        "sample_submission['price'] = sub_predict_catboost\n",
        "sample_submission.to_csv('catboost_submission.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "6NqleEcJdvOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3: Tabular NN"
      ],
      "metadata": {
        "id": "SDb4hZNgdvOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Построим обычную сеть:"
      ],
      "metadata": {
        "id": "x86VSKJvdvOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(5)"
      ],
      "metadata": {
        "trusted": true,
        "id": "VPMxbKBvdvOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Dense NN"
      ],
      "metadata": {
        "id": "wmF0YcpRdvOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(L.Dense(512, input_dim=X_train.shape[1], activation=\"relu\"))\n",
        "model.add(L.Dropout(0.5))\n",
        "model.add(L.Dense(256, activation=\"relu\"))\n",
        "model.add(L.Dropout(0.5))\n",
        "model.add(L.Dense(1, activation=\"linear\"))"
      ],
      "metadata": {
        "trusted": true,
        "id": "pEQYDfvzdvOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "B_mHB4H_dvOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "model.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "gn0kxHWedvOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('../working/best_model.hdf5' , monitor=['val_MAPE'], verbose=0  , mode='min')\n",
        "earlystop = EarlyStopping(monitor='val_MAPE', patience=50, restore_best_weights=True,)\n",
        "callbacks_list = [checkpoint, earlystop]"
      ],
      "metadata": {
        "trusted": true,
        "id": "cey2wQutdvOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit"
      ],
      "metadata": {
        "id": "WV1ZvUdjdvOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=500, # фактически мы обучаем пока EarlyStopping не остановит обучение\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=callbacks_list,\n",
        "                    verbose=0,\n",
        "                   )"
      ],
      "metadata": {
        "trusted": true,
        "id": "MLevS6Y3dvOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Loss')\n",
        "plt.plot(history.history['MAPE'], label='train')\n",
        "plt.plot(history.history['val_MAPE'], label='test')\n",
        "plt.show();"
      ],
      "metadata": {
        "trusted": true,
        "id": "dvcT5is9dvOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('../working/best_model.hdf5')\n",
        "model.save('../working/nn_1.hdf5')"
      ],
      "metadata": {
        "trusted": true,
        "id": "KMHexoTfdvOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_nn1 = model.predict(X_test)\n",
        "print(f\"TEST mape: {(mape(y_test, test_predict_nn1[:,0]))*100:0.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "WDS_N9WPdvOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_predict_nn1 = model.predict(X_sub)\n",
        "sample_submission['price'] = sub_predict_nn1[:,0]\n",
        "sample_submission.to_csv('nn1_submission.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "d25oBmn7dvOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рекомендации для улучшения Model 3:    \n",
        "* В нейросеть желательно подавать данные с распределением, близким к нормальному, поэтому от некоторых числовых признаков имеет смысл взять логарифм перед нормализацией. Пример:\n",
        "`modelDateNorm = np.log(2020 - data['modelDate'])`\n",
        "Статья по теме: https://habr.com/ru/company/ods/blog/325422\n",
        "\n",
        "* Извлечение числовых значений из текста:\n",
        "Парсинг признаков 'engineDisplacement', 'enginePower', 'Владение' для извлечения числовых значений.\n",
        "\n",
        "* Cокращение размерности категориальных признаков\n",
        "Признак name 'name' содержит данные, которые уже есть в других столбцах ('enginePower', 'engineDisplacement', 'vehicleTransmission'), поэтому эти данные можно удалить. Затем следует еще сильнее сократить размерность, например, выделив наличие xDrive в качестве отдельного признака."
      ],
      "metadata": {
        "id": "kNTG0aDUdvOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4: NLP + Multiple Inputs"
      ],
      "metadata": {
        "id": "rACINAczdvOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.description"
      ],
      "metadata": {
        "id": "G7Dws4PSdvOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TOKENIZER\n",
        "# The maximum number of words to be used. (most frequent)\n",
        "MAX_WORDS = 100000\n",
        "# Max number of words in each complaint.\n",
        "MAX_SEQUENCE_LENGTH = 256"
      ],
      "metadata": {
        "id": "NAqgXoERdvOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split данных\n",
        "text_train = data.description.iloc[X_train.index]\n",
        "text_test = data.description.iloc[X_test.index]\n",
        "text_sub = data.description.iloc[X_sub.index]"
      ],
      "metadata": {
        "id": "280DXCoKdvOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer"
      ],
      "metadata": {
        "id": "mFeUbHckdvOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "tokenize = Tokenizer(num_words=MAX_WORDS)\n",
        "tokenize.fit_on_texts(data.description)"
      ],
      "metadata": {
        "id": "EzcbmylRdvOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize.word_index"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "id": "OgNOjw2SdvOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "text_train_sequences = sequence.pad_sequences(tokenize.texts_to_sequences(text_train), maxlen=MAX_SEQUENCE_LENGTH)\n",
        "text_test_sequences = sequence.pad_sequences(tokenize.texts_to_sequences(text_test), maxlen=MAX_SEQUENCE_LENGTH)\n",
        "text_sub_sequences = sequence.pad_sequences(tokenize.texts_to_sequences(text_sub), maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print(text_train_sequences.shape, text_test_sequences.shape, text_sub_sequences.shape, )"
      ],
      "metadata": {
        "id": "eXc9V_zJdvOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# вот так теперь выглядит наш текст\n",
        "print(text_train.iloc[6])\n",
        "print(text_train_sequences[6])"
      ],
      "metadata": {
        "id": "VezmKhjtdvOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN NLP"
      ],
      "metadata": {
        "id": "WISxY9QRdvOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_nlp = Sequential()\n",
        "model_nlp.add(L.Input(shape=MAX_SEQUENCE_LENGTH, name=\"seq_description\"))\n",
        "model_nlp.add(L.Embedding(len(tokenize.word_index)+1, MAX_SEQUENCE_LENGTH,))\n",
        "model_nlp.add(L.LSTM(256, return_sequences=True))\n",
        "model_nlp.add(L.Dropout(0.5))\n",
        "model_nlp.add(L.LSTM(128,))\n",
        "model_nlp.add(L.Dropout(0.25))\n",
        "model_nlp.add(L.Dense(64, activation=\"relu\"))\n",
        "model_nlp.add(L.Dropout(0.25))"
      ],
      "metadata": {
        "id": "YjsEZ8HydvOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "aINUV4dHdvOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp = Sequential()\n",
        "model_mlp.add(L.Dense(512, input_dim=X_train.shape[1], activation=\"relu\"))\n",
        "model_mlp.add(L.Dropout(0.5))\n",
        "model_mlp.add(L.Dense(256, activation=\"relu\"))\n",
        "model_mlp.add(L.Dropout(0.5))"
      ],
      "metadata": {
        "id": "K4_bZ1ojdvOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiple Inputs NN"
      ],
      "metadata": {
        "id": "WGjlm1lYdvOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combinedInput = L.concatenate([model_nlp.output, model_mlp.output])\n",
        "# being our regression head\n",
        "head = L.Dense(64, activation=\"relu\")(combinedInput)\n",
        "head = L.Dense(1, activation=\"linear\")(head)\n",
        "\n",
        "model = Model(inputs=[model_nlp.input, model_mlp.input], outputs=head)"
      ],
      "metadata": {
        "id": "MeUm_FptdvOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "id": "EnXsoA40dvOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit"
      ],
      "metadata": {
        "id": "fb24ePIvdvOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "model.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])"
      ],
      "metadata": {
        "id": "Kz9UshJWdvOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('../working/best_model.hdf5', monitor=['val_MAPE'], verbose=0, mode='min')\n",
        "earlystop = EarlyStopping(monitor='val_MAPE', patience=10, restore_best_weights=True,)\n",
        "callbacks_list = [checkpoint, earlystop]"
      ],
      "metadata": {
        "id": "dpG8fXjVdvOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([text_train_sequences, X_train], y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=500, # фактически мы обучаем пока EarlyStopping не остановит обучение\n",
        "                    validation_data=([text_test_sequences, X_test], y_test),\n",
        "                    callbacks=callbacks_list\n",
        "                   )"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "id": "_CCdJ_PNdvOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Loss')\n",
        "plt.plot(history.history['MAPE'], label='train')\n",
        "plt.plot(history.history['val_MAPE'], label='test')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "TaERbXIYdvOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('../working/best_model.hdf5')\n",
        "model.save('../working/nn_mlp_nlp.hdf5')"
      ],
      "metadata": {
        "id": "1wo74m_sdvOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_nn2 = model.predict([text_test_sequences, X_test])\n",
        "print(f\"TEST mape: {(mape(y_test, test_predict_nn2[:,0]))*100:0.2f}%\")"
      ],
      "metadata": {
        "id": "ncms5nfBdvOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_predict_nn2 = model.predict([text_sub_sequences, X_sub])\n",
        "sample_submission['price'] = sub_predict_nn2[:,0]\n",
        "sample_submission.to_csv('nn2_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "wuCiUsY1dvOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Идеи для улучшения NLP части:\n",
        "* Выделить из описаний часто встречающиеся блоки текста, заменив их на кодовые слова или удалив\n",
        "* Сделать предобработку текста, например, сделать лемматизацию - алгоритм ставящий все слова в форму по умолчанию (глаголы в инфинитив и т. д.), чтобы токенайзер не преобразовывал разные формы слова в разные числа\n",
        "Статья по теме: https://habr.com/ru/company/Voximplant/blog/446738/\n",
        "* Поработать над алгоритмами очистки и аугментации текста"
      ],
      "metadata": {
        "id": "WNoGjBXrdvOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 5: Добавляем картинки"
      ],
      "metadata": {
        "id": "QWZmwaIMdvOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "5u2hgF5jdvOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# убедимся, что цены и фото подгрузились верно\n",
        "plt.figure(figsize = (12,8))\n",
        "\n",
        "random_image = train.sample(n = 9)\n",
        "random_image_paths = random_image['sell_id'].values\n",
        "random_image_cat = random_image['price'].values\n",
        "\n",
        "for index, path in enumerate(random_image_paths):\n",
        "    im = PIL.Image.open(DATA_DIR+'img/img/' + str(path) + '.jpg')\n",
        "    plt.subplot(3, 3, index + 1)\n",
        "    plt.imshow(im)\n",
        "    plt.title('price: ' + str(random_image_cat[index]))\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gcnzmDa7dvOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = (320, 240)\n",
        "\n",
        "def get_image_array(index):\n",
        "    images_train = []\n",
        "    for index, sell_id in enumerate(data['sell_id'].iloc[index].values):\n",
        "        image = cv2.imread(DATA_DIR + 'img/img/' + str(sell_id) + '.jpg')\n",
        "        assert(image is not None)\n",
        "        image = cv2.resize(image, size)\n",
        "        images_train.append(image)\n",
        "    images_train = np.array(images_train)\n",
        "    print('images shape', images_train.shape, 'dtype', images_train.dtype)\n",
        "    return(images_train)\n",
        "\n",
        "images_train = get_image_array(X_train.index)\n",
        "images_test = get_image_array(X_test.index)\n",
        "images_sub = get_image_array(X_sub.index)"
      ],
      "metadata": {
        "id": "NimzZz0CdvOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### albumentations"
      ],
      "metadata": {
        "id": "SWhheVBSdvOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from albumentations import (\n",
        "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
        "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
        "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
        "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose\n",
        ")\n",
        "\n",
        "\n",
        "#пример взят из официальной документации: https://albumentations.readthedocs.io/en/latest/examples.html\n",
        "augmentation = Compose([\n",
        "    HorizontalFlip(),\n",
        "    OneOf([\n",
        "        IAAAdditiveGaussianNoise(),\n",
        "        GaussNoise(),\n",
        "    ], p=0.2),\n",
        "    OneOf([\n",
        "        MotionBlur(p=0.2),\n",
        "        MedianBlur(blur_limit=3, p=0.1),\n",
        "        Blur(blur_limit=3, p=0.1),\n",
        "    ], p=0.2),\n",
        "    ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=15, p=1),\n",
        "    OneOf([\n",
        "        OpticalDistortion(p=0.3),\n",
        "        GridDistortion(p=0.1),\n",
        "        IAAPiecewiseAffine(p=0.3),\n",
        "    ], p=0.2),\n",
        "    OneOf([\n",
        "        CLAHE(clip_limit=2),\n",
        "        IAASharpen(),\n",
        "        IAAEmboss(),\n",
        "        RandomBrightnessContrast(),\n",
        "    ], p=0.3),\n",
        "    HueSaturationValue(p=0.3),\n",
        "], p=1)\n",
        "\n",
        "#пример\n",
        "plt.figure(figsize = (12,8))\n",
        "for i in range(9):\n",
        "    img = augmentation(image = images_train[0])['image']\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "slmB44cndvOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_augmentations(images):\n",
        "  print('применение аугментаций', end = '')\n",
        "  augmented_images = np.empty(images.shape)\n",
        "  for i in range(images.shape[0]):\n",
        "    if i % 200 == 0:\n",
        "      print('.', end = '')\n",
        "    augment_dict = augmentation(image = images[i])\n",
        "    augmented_image = augment_dict['image']\n",
        "    augmented_images[i] = augmented_image\n",
        "  print('')\n",
        "  return augmented_images"
      ],
      "metadata": {
        "id": "vjDpp3rYdvOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tf.data.Dataset\n",
        "Если все изображения мы будем хранить в памяти, то может возникнуть проблема ее нехватки. Не храните все изображения в памяти целиком!\n",
        "\n",
        "Метод .fit() модели keras может принимать либо данные в виде массивов или тензоров, либо разного рода итераторы, из которых наиболее современным и гибким является [tf.data.Dataset](https://www.tensorflow.org/guide/data). Он представляет собой конвейер, то есть мы указываем, откуда берем данные и какую цепочку преобразований с ними выполняем. Далее мы будем работать с tf.data.Dataset.\n",
        "\n",
        "Dataset хранит информацию о конечном или бесконечном наборе кортежей (tuple) с данными и может возвращать эти наборы по очереди. Например, данными могут быть пары (input, target) для обучения нейросети. С данными можно осуществлять преобразования, которые осуществляются по мере необходимости ([lazy evaluation](https://ru.wikipedia.org/wiki/%D0%9B%D0%B5%D0%BD%D0%B8%D0%B2%D1%8B%D0%B5_%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F)).\n",
        "\n",
        "`tf.data.Dataset.from_tensor_slices(data)` - создает датасет из данных, которые представляют собой либо массив, либо кортеж из массивов. Деление осуществляется по первому индексу каждого массива. Например, если `data = (np.zeros((128, 256, 256)), np.zeros(128))`, то датасет будет содержать 128 элементов, каждый из которых содержит один массив 256x256 и одно число.\n",
        "\n",
        "`dataset2 = dataset1.map(func)` - применение функции к датасету; функция должна принимать столько аргументов, каков размер кортежа в датасете 1 и возвращать столько, сколько нужно иметь в датасете 2. Пусть, например, датасет содержит изображения и метки, а нам нужно создать датасет только из изображений, тогда мы напишем так: `dataset2 = dataset.map(lambda img, label: img)`.\n",
        "\n",
        "`dataset2 = dataset1.batch(8)` - группировка по батчам; если датасет 2 должен вернуть один элемент, то он берет из датасета 1 восемь элементов, склеивает их (нулевой индекс результата - номер элемента) и возвращает.\n",
        "\n",
        "`dataset.__iter__()` - превращение датасета в итератор, из которого можно получать элементы методом `.__next__()`. Итератор, в отличие от самого датасета, хранит позицию текущего элемента. Можно также перебирать датасет циклом for.\n",
        "\n",
        "`dataset2 = dataset1.repeat(X)` - датасет 2 будет повторять датасет 1 X раз.\n",
        "\n",
        "Если нам нужно взять из датасета 1000 элементов и использовать их как тестовые, а остальные как обучающие, то мы напишем так:\n",
        "\n",
        "`test_dataset = dataset.take(1000)\n",
        "train_dataset = dataset.skip(1000)`\n",
        "\n",
        "Датасет по сути неизменен: такие операции, как map, batch, repeat, take, skip никак не затрагивают оригинальный датасет. Если датасет хранит элементы [1, 2, 3], то выполнив 3 раза подряд функцию dataset.take(1) мы получим 3 новых датасета, каждый из которых вернет число 1. Если же мы выполним функцию dataset.skip(1), мы получим датасет, возвращающий числа [2, 3], но исходный датасет все равно будет возвращать [1, 2, 3] каждый раз, когда мы его перебираем.\n",
        "\n",
        "tf.Dataset всегда выполняется в graph-режиме (в противоположность eager-режиму), поэтому либо преобразования (`.map()`) должны содержать только tensorflow-функции, либо мы должны использовать tf.py_function в качестве обертки для функций, вызываемых в `.map()`. Подробнее можно прочитать [здесь](https://www.tensorflow.org/guide/data#applying_arbitrary_python_logic)."
      ],
      "metadata": {
        "id": "3RWLVxoudvOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP part\n",
        "tokenize = Tokenizer(num_words=MAX_WORDS)\n",
        "tokenize.fit_on_texts(data.description)"
      ],
      "metadata": {
        "id": "JclIu_v1dvOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image):\n",
        "    return augmentation(image = image.numpy())['image']\n",
        "\n",
        "def tokenize_(descriptions):\n",
        "  return sequence.pad_sequences(tokenize.texts_to_sequences(descriptions), maxlen = MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "def tokenize_text(text):\n",
        "    return tokenize_([text.numpy().decode('utf-8')])[0]\n",
        "\n",
        "def tf_process_train_dataset_element(image, table_data, text, price):\n",
        "    im_shape = image.shape\n",
        "    [image,] = tf.py_function(process_image, [image], [tf.uint8])\n",
        "    image.set_shape(im_shape)\n",
        "    [text,] = tf.py_function(tokenize_text, [text], [tf.int32])\n",
        "    return (image, table_data, text), price\n",
        "\n",
        "def tf_process_val_dataset_element(image, table_data, text, price):\n",
        "    [text,] = tf.py_function(tokenize_text, [text], [tf.int32])\n",
        "    return (image, table_data, text), price\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    images_train, X_train, data.description.iloc[X_train.index], y_train\n",
        "    )).map(tf_process_train_dataset_element)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    images_test, X_test, data.description.iloc[X_test.index], y_test\n",
        "    )).map(tf_process_val_dataset_element)\n",
        "\n",
        "y_sub = np.zeros(len(X_sub))\n",
        "sub_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    images_sub, X_sub, data.description.iloc[X_sub.index], y_sub\n",
        "    )).map(tf_process_val_dataset_element)\n",
        "\n",
        "#проверяем, что нет ошибок (не будет выброшено исключение):\n",
        "train_dataset.__iter__().__next__();\n",
        "test_dataset.__iter__().__next__();\n",
        "sub_dataset.__iter__().__next__();"
      ],
      "metadata": {
        "id": "sid25j_IdvOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Строим сверточную сеть для анализа изображений без \"головы\""
      ],
      "metadata": {
        "id": "mf5qcnNedvOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#нормализация включена в состав модели EfficientNetB3, поэтому на вход она принимает данные типа uint8\n",
        "efficientnet_model = tf.keras.applications.efficientnet.EfficientNetB3(weights = 'imagenet', include_top = False, input_shape = (size[1], size[0], 3))\n",
        "efficientnet_output = L.GlobalAveragePooling2D()(efficientnet_model.output)"
      ],
      "metadata": {
        "id": "KELIkxy8dvOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#строим нейросеть для анализа табличных данных\n",
        "tabular_model = Sequential([\n",
        "    L.Input(shape = X.shape[1]),\n",
        "    L.Dense(512, activation = 'relu'),\n",
        "    L.Dropout(0.5),\n",
        "    L.Dense(256, activation = 'relu'),\n",
        "    L.Dropout(0.5),\n",
        "    ])"
      ],
      "metadata": {
        "id": "TFqF7iwRdvOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP\n",
        "nlp_model = Sequential([\n",
        "    L.Input(shape=MAX_SEQUENCE_LENGTH, name=\"seq_description\"),\n",
        "    L.Embedding(len(tokenize.word_index)+1, MAX_SEQUENCE_LENGTH,),\n",
        "    L.LSTM(256, return_sequences=True),\n",
        "    L.Dropout(0.5),\n",
        "    L.LSTM(128),\n",
        "    L.Dropout(0.25),\n",
        "    L.Dense(64),\n",
        "    ])"
      ],
      "metadata": {
        "id": "naG8TohRdvOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#объединяем выходы трех нейросетей\n",
        "combinedInput = L.concatenate([efficientnet_output, tabular_model.output, nlp_model.output])\n",
        "\n",
        "# being our regression head\n",
        "head = L.Dense(256, activation=\"relu\")(combinedInput)\n",
        "head = L.Dense(1,)(head)\n",
        "\n",
        "model = Model(inputs=[efficientnet_model.input, tabular_model.input, nlp_model.input], outputs=head)\n",
        "model.summary()"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "id": "zvUqBnlWdvOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.005)\n",
        "model.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])"
      ],
      "metadata": {
        "id": "teuUd6dndvOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('../working/best_model.hdf5', monitor=['val_MAPE'], verbose=0, mode='min')\n",
        "earlystop = EarlyStopping(monitor='val_MAPE', patience=10, restore_best_weights=True,)\n",
        "callbacks_list = [checkpoint, earlystop]"
      ],
      "metadata": {
        "id": "Mvv-FCewdvOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset.batch(30),\n",
        "                    epochs=100,\n",
        "                    validation_data = test_dataset.batch(30),\n",
        "                    callbacks=callbacks_list\n",
        "                   )"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "id": "WOBU3yB1dvOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Loss')\n",
        "plt.plot(history.history['MAPE'], label='train')\n",
        "plt.plot(history.history['val_MAPE'], label='test')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "Q5yX_ZKXdvOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('../working/best_model.hdf5')\n",
        "model.save('../working/nn_final.hdf5')"
      ],
      "metadata": {
        "id": "phs5Ef6XdvOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_nn3 = model.predict(test_dataset.batch(30))\n",
        "print(f\"TEST mape: {(mape(y_test, test_predict_nn3[:,0]))*100:0.2f}%\")"
      ],
      "metadata": {
        "id": "bJKeMqlfdvOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_predict_nn3 = model.predict(sub_dataset.batch(30))\n",
        "sample_submission['price'] = sub_predict_nn3[:,0]\n",
        "sample_submission.to_csv('nn3_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "Lb9FI07fdvOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Общие рекомендации:\n",
        "* Попробовать разные архитектуры\n",
        "* Провести более детальный анализ результатов\n",
        "* Попробовать различные подходы в управление LR и оптимизаторы\n",
        "* Поработать с таргетом\n",
        "* Использовать Fine-tuning\n",
        "\n",
        "#### Tabular\n",
        "* В нейросеть желательно подавать данные с распределением, близким к нормальному, поэтому от некоторых числовых признаков имеет смысл взять логарифм перед нормализацией. Пример:\n",
        "`modelDateNorm = np.log(2020 - data['modelDate'])`\n",
        "Статья по теме: https://habr.com/ru/company/ods/blog/325422\n",
        "\n",
        "* Извлечение числовых значений из текста:\n",
        "Парсинг признаков 'engineDisplacement', 'enginePower', 'Владение' для извлечения числовых значений.\n",
        "\n",
        "* Cокращение размерности категориальных признаков\n",
        "Признак name 'name' содержит данные, которые уже есть в других столбцах ('enginePower', 'engineDisplacement', 'vehicleTransmission'). Можно удалить эти данные. Затем можно еще сильнее сократить размерность, например выделив наличие xDrive в качестве отдельного признака.\n",
        "\n",
        "* Поработать над Feature engineering\n",
        "\n",
        "\n",
        "\n",
        "#### NLP\n",
        "* Выделить из описаний часто встречающиеся блоки текста, заменив их на кодовые слова или удалив\n",
        "* Сделать предобработку текста, например сделать лемматизацию - алгоритм ставящий все слова в форму по умолчанию (глаголы в инфинитив и т. д.), чтобы токенайзер не преобразовывал разные формы слова в разные числа\n",
        "Статья по теме: https://habr.com/ru/company/Voximplant/blog/446738/\n",
        "* Поработать над алгоритмами очистки и аугментации текста\n",
        "\n",
        "\n",
        "\n",
        "#### CV\n",
        "* Попробовать различные аугментации\n",
        "* Fine-tuning"
      ],
      "metadata": {
        "id": "Tb4sopDidvOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Blend"
      ],
      "metadata": {
        "id": "ef40z399dvOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blend_predict = (test_predict_catboost + test_predict_nn3[:,0]) / 2\n",
        "print(f\"TEST mape: {(mape(y_test, blend_predict))*100:0.2f}%\")"
      ],
      "metadata": {
        "id": "Ybh2PFH8dvOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blend_sub_predict = (sub_predict_catboost + sub_predict_nn3[:,0]) / 2\n",
        "sample_submission['price'] = blend_sub_predict\n",
        "sample_submission.to_csv('blend_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "CxY_KQzVdvOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Bonus: проброс признака"
      ],
      "metadata": {
        "id": "_VRrshRGdvOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP\n",
        "model_mlp = Sequential()\n",
        "model_mlp.add(L.Dense(512, input_dim=X_train.shape[1], activation=\"relu\"))\n",
        "model_mlp.add(L.Dropout(0.5))\n",
        "model_mlp.add(L.Dense(256, activation=\"relu\"))\n",
        "model_mlp.add(L.Dropout(0.5))"
      ],
      "metadata": {
        "trusted": true,
        "id": "v4IPvq78dvOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FEATURE Input\n",
        "# Iput\n",
        "productiondate = L.Input(shape=[1], name=\"productiondate\")\n",
        "# Embeddings layers\n",
        "emb_productiondate = L.Embedding(len(X.productionDate.unique().tolist())+1, 20)(productiondate)\n",
        "f_productiondate = L.Flatten()(emb_productiondate)"
      ],
      "metadata": {
        "trusted": true,
        "id": "lx8T_dzAdvOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combinedInput = L.concatenate([model_mlp.output, f_productiondate,])\n",
        "# being our regression head\n",
        "head = L.Dense(64, activation=\"relu\")(combinedInput)\n",
        "head = L.Dense(1, activation=\"linear\")(head)\n",
        "\n",
        "model = Model(inputs=[model_mlp.input, productiondate], outputs=head)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ifuqbNlGdvOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "Xtr24ddGdvOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "model.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "VO0xBcsAdvOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train, X_train.productionDate.values], y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=500, # фактически мы обучаем пока EarlyStopping не остановит обучение\n",
        "                    validation_data=([X_test, X_test.productionDate.values], y_test),\n",
        "                    callbacks=callbacks_list\n",
        "                   )"
      ],
      "metadata": {
        "trusted": true,
        "id": "CkhxMEAtdvOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('../working/best_model.hdf5')\n",
        "test_predict_nn_bonus = model.predict([X_test, X_test.productionDate.values])\n",
        "print(f\"TEST mape: {(mape(y_test, test_predict_nn_bonus[:,0]))*100:0.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "vUTjrrlhdvOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8DwCAY86dvOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# "
      ],
      "metadata": {
        "id": "L_8oZWJPdvOr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}