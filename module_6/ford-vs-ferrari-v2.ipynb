{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> Ford vs Ferrari  \n#### <center> Необходимо построить модель классификации изображений автомобилей по их фотографиям\n\n---    \nИТОГИ РАБОТЫ НАД ПРОЕКТОМ:\n\n+ Построить свой классификатор изображений.\n+ Применить различные методы предобработки изображений.\n+ Задействовать сразу несколько методов обучения (fine-tuning, transfer learning и так далее).\n+ Научиться использовать предобученные модели для решения своих задач.\n+ Найти и используете в работе State of the Art (SOTA)-модели.\n---","metadata":{}},{"cell_type":"markdown","source":"<center> <img src=\"https://tribaltribune.org/wp-content/uploads/2020/01/960x0-1-1-900x515.jpg\"/>","metadata":{}},{"cell_type":"markdown","source":"# Импорт библиотек и данных\n","metadata":{}},{"cell_type":"code","source":"# Проверим подключена ли видеокарта\n!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-01-25T03:45:07.147004Z","iopub.execute_input":"2022-01-25T03:45:07.147327Z","iopub.status.idle":"2022-01-25T03:45:07.912872Z","shell.execute_reply.started":"2022-01-25T03:45:07.147294Z","shell.execute_reply":"2022-01-25T03:45:07.911880Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Установим настраиваемый генератор данных изображений ImageDataAugmentor для аугментации данных\n!pip install git+https://github.com/mjkvaak/ImageDataAugmentor","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:19:14.564115Z","iopub.execute_input":"2022-01-24T22:19:14.564445Z","iopub.status.idle":"2022-01-24T22:19:26.745339Z","shell.execute_reply.started":"2022-01-24T22:19:14.564407Z","shell.execute_reply":"2022-01-24T22:19:26.744378Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint,CSVLogger, EarlyStopping\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.layers import *\nfrom ImageDataAugmentor.image_data_augmentor import *\nimport albumentations\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom tensorflow.keras.applications import EfficientNetB2\nfrom keras.layers import BatchNormalization\n\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#увеличим дефолтный размер графиков\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#графики в svg выглядят более четкими\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"../input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:19:26.747932Z","iopub.execute_input":"2022-01-24T22:19:26.748175Z","iopub.status.idle":"2022-01-24T22:19:33.885423Z","shell.execute_reply.started":"2022-01-24T22:19:26.748146Z","shell.execute_reply":"2022-01-24T22:19:33.884520Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# В setup выносим основные настройки: так удобнее их перебирать в дальнейшем.\n\nEPOCHS               = 5  # эпох на обучение (далее попробуем изменить количество эпох на обучение)\nBATCH_SIZE           = 64 # уменьшаем batch если сеть большая, иначе не поместится в память на GPU\nLR                   = 1e-4\nVAL_SPLIT            = 0.15 # сколько данных выделяем на тест = 15%\n\nCLASS_NUM            = 10  # количество классов в нашей задаче\nIMG_SIZE             = 224 # какого размера подаем изображения в сеть\nIMG_CHANNELS         = 3   # у RGB 3 канала\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '../input/sf-dl-car-classification/'\nPATH = \"../working/car/\" # рабочая директория","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:19:33.886734Z","iopub.execute_input":"2022-01-24T22:19:33.887564Z","iopub.status.idle":"2022-01-24T22:19:33.893841Z","shell.execute_reply.started":"2022-01-24T22:19:33.887504Z","shell.execute_reply":"2022-01-24T22:19:33.893173Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Фиксируем RANDOM_SEED, чтобы эксперименты были воспроизводимы\nRANDOM_SEED=42 ","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:19:33.896068Z","iopub.execute_input":"2022-01-24T22:19:33.897139Z","iopub.status.idle":"2022-01-24T22:19:33.917801Z","shell.execute_reply.started":"2022-01-24T22:19:33.897079Z","shell.execute_reply":"2022-01-24T22:19:33.916922Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# EDA (Разведывательный анализ данных)","metadata":{}},{"cell_type":"code","source":"# Ознакомимся с нашими данными\ntrain_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:19:33.919033Z","iopub.execute_input":"2022-01-24T22:19:33.920177Z","iopub.status.idle":"2022-01-24T22:19:33.973546Z","shell.execute_reply.started":"2022-01-24T22:19:33.920135Z","shell.execute_reply":"2022-01-24T22:19:33.972828Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:19:33.975008Z","iopub.execute_input":"2022-01-24T22:19:33.975541Z","iopub.status.idle":"2022-01-24T22:19:33.999583Z","shell.execute_reply.started":"2022-01-24T22:19:33.975503Z","shell.execute_reply":"2022-01-24T22:19:33.998807Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_df.Category.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:19:34.000982Z","iopub.execute_input":"2022-01-24T22:19:34.001318Z","iopub.status.idle":"2022-01-24T22:19:34.010689Z","shell.execute_reply.started":"2022-01-24T22:19:34.001280Z","shell.execute_reply":"2022-01-24T22:19:34.009784Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Как мы видим, данные сдержат 10 классов, а распределение классов достаточно равномерное.","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:02.378349Z","iopub.execute_input":"2022-01-23T18:31:02.378625Z","iopub.status.idle":"2022-01-23T18:31:02.384977Z","shell.execute_reply.started":"2022-01-23T18:31:02.378595Z","shell.execute_reply":"2022-01-23T18:31:02.383662Z"}}},{"cell_type":"code","source":"print('Распаковываем картинки')\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(DATA_PATH+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:19:34.012828Z","iopub.execute_input":"2022-01-24T22:19:34.013480Z","iopub.status.idle":"2022-01-24T22:19:59.432668Z","shell.execute_reply.started":"2022-01-24T22:19:34.013441Z","shell.execute_reply":"2022-01-24T22:19:59.431796Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print('Выведем случайный пример изображений:')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:19:59.434008Z","iopub.execute_input":"2022-01-24T22:19:59.434297Z","iopub.status.idle":"2022-01-24T22:20:00.281887Z","shell.execute_reply.started":"2022-01-24T22:19:59.434255Z","shell.execute_reply":"2022-01-24T22:20:00.281156Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"В соответствии с представленными изображениями, можно сделать предположение о том что классы представляют из себя марки автомобилей","metadata":{}},{"cell_type":"code","source":"# Посмотрим на примеры картинок и их размеры, чтобы понимать, как их лучше обрабатывать и сжимать\nimage = PIL.Image.open(PATH+'/train/0/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:20:00.282931Z","iopub.execute_input":"2022-01-24T22:20:00.283195Z","iopub.status.idle":"2022-01-24T22:20:01.270537Z","shell.execute_reply.started":"2022-01-24T22:20:00.283164Z","shell.execute_reply":"2022-01-24T22:20:01.269879Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Аугментация данных","metadata":{}},{"cell_type":"markdown","source":"**Аугментация данных с помощью ImageDataGenerator:**","metadata":{}},{"cell_type":"markdown","source":"```python\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    rotation_range = 5,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    validation_split=VAL_SPLIT, # set validation split\n    horizontal_flip=False)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n```","metadata":{"execution":{"iopub.status.busy":"2022-01-23T19:41:02.671112Z","iopub.execute_input":"2022-01-23T19:41:02.671404Z","iopub.status.idle":"2022-01-23T19:41:02.676552Z","shell.execute_reply.started":"2022-01-23T19:41:02.67137Z","shell.execute_reply":"2022-01-23T19:41:02.675905Z"}}},{"cell_type":"markdown","source":"**Аугментация данных с помощью albumentations:**","metadata":{}},{"cell_type":"code","source":"AUGMENTATIONS = albumentations.Compose([\n    albumentations.transforms.HorizontalFlip(p=0.5),\n#     albumentations.transforms.Flip(p=0.5),\n    albumentations.transforms.FancyPCA (alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n#     albumentations.HueSaturationValue(p=0.8),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.8),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:20:01.271871Z","iopub.execute_input":"2022-01-24T22:20:01.272335Z","iopub.status.idle":"2022-01-24T22:20:01.279807Z","shell.execute_reply.started":"2022-01-24T22:20:01.272296Z","shell.execute_reply":"2022-01-24T22:20:01.278521Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataAugmentor(\n        rescale=1./255,\n        augment=AUGMENTATIONS,\n        validation_split=VAL_SPLIT)\n\n# test_datagen = ImageDataAugmentor(rescale=1. / 255)\ntest_datagen = ImageDataGenerator(rescale=1. / 255)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:20:01.281422Z","iopub.execute_input":"2022-01-24T22:20:01.282064Z","iopub.status.idle":"2022-01-24T22:20:01.291541Z","shell.execute_reply.started":"2022-01-24T22:20:01.282025Z","shell.execute_reply":"2022-01-24T22:20:01.290492Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Генерация данных","metadata":{}},{"cell_type":"code","source":"# Завернём наши данные в генератор: \ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:20:01.297836Z","iopub.execute_input":"2022-01-24T22:20:01.298361Z","iopub.status.idle":"2022-01-24T22:20:02.534346Z","shell.execute_reply.started":"2022-01-24T22:20:01.298326Z","shell.execute_reply":"2022-01-24T22:20:02.533594Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Построение модели","metadata":{}},{"cell_type":"markdown","source":"**Предобученная сверточная нейронная сеть Inception-ResNet-v2**:\n```python\nbase_model = InceptionResNetV2(weights='imagenet',include_top=False, input_shape = input_shape)\n```\n> (Данная сеть не подходит, так как сеть является 164 слоями глубоко и может классифицировать изображения в 1 000 категорий объектов, таких как клавиатура, мышь, карандаш и многие животные)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T17:45:02.803534Z","iopub.execute_input":"2022-01-24T17:45:02.804257Z","iopub.status.idle":"2022-01-24T17:45:10.493262Z","shell.execute_reply.started":"2022-01-24T17:45:02.804196Z","shell.execute_reply":"2022-01-24T17:45:10.492503Z"}}},{"cell_type":"markdown","source":"**Предобученная нейронная сеть EfficientNetB2**:\n```python\nbase_model = EfficientNetB2(include_top=False, weights='imagenet', input_tensor=None, \n    pooling=None, classes=1000, classifier_activation='softmax')\n```","metadata":{}},{"cell_type":"markdown","source":"**Последовательная архитектура нейронной сети**\n```python\nbase_model = Sequential()\nbase_model.add(Dense(224, input_shape=(input_shape)))\nbase_model.add(Activation('relu'))\nbase_model.add(Conv2D(224, (3, 3)))\nbase_model.add(Activation('relu'))\nbase_model.add(Dense(64))\nbase_model.add(Activation('relu'))\nbase_model.add(Dropout(0.5))\nbase_model.add(Dense(10))\nbase_model.add(Activation('sigmoid'))\nbase_model.add(BatchNormalization())\n```","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:54:25.436091Z","iopub.execute_input":"2022-01-24T19:54:25.436382Z","iopub.status.idle":"2022-01-24T19:54:25.439949Z","shell.execute_reply.started":"2022-01-24T19:54:25.436346Z","shell.execute_reply":"2022-01-24T19:54:25.439294Z"}}},{"cell_type":"markdown","source":"> Все вышеперечисленые модли не дал таких результатов как Xception. Соответственно далее будет использоваться Xception.\nПосмотреть результаты работы других моделей можно пункте [Прочее](#Прочее)","metadata":{}},{"cell_type":"code","source":"# Предобученная сеть Xception:\nbase_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:20:02.535461Z","iopub.execute_input":"2022-01-24T22:20:02.536253Z","iopub.status.idle":"2022-01-24T22:20:06.430927Z","shell.execute_reply.started":"2022-01-24T22:20:02.536213Z","shell.execute_reply":"2022-01-24T22:20:06.430161Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:20:06.432307Z","iopub.execute_input":"2022-01-24T22:20:06.432546Z","iopub.status.idle":"2022-01-24T22:20:06.503576Z","shell.execute_reply.started":"2022-01-24T22:20:06.432513Z","shell.execute_reply":"2022-01-24T22:20:06.502784Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Устанавливаем новую «голову» (head):\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.25)(x)\n# and a logistic layer -- let's say we have 10 classes\npredictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(learning_rate=LR), metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:20:06.504688Z","iopub.execute_input":"2022-01-24T22:20:06.505375Z","iopub.status.idle":"2022-01-24T22:20:06.551729Z","shell.execute_reply.started":"2022-01-24T22:20:06.505332Z","shell.execute_reply":"2022-01-24T22:20:06.551050Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:20:06.553146Z","iopub.execute_input":"2022-01-24T22:20:06.553395Z","iopub.status.idle":"2022-01-24T22:20:06.620449Z","shell.execute_reply.started":"2022-01-24T22:20:06.553361Z","shell.execute_reply":"2022-01-24T22:20:06.619760Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Обучение модели","metadata":{}},{"cell_type":"code","source":"# Добавим ModelCheckpoint. Эта функция позволяет сохранять прогресс обучения модели, чтобы в нужный момент можно было его подгрузить\n# и дообучить модель:\ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\ncallbacks_list = [checkpoint]\n\ncallbacks_stop = EarlyStopping(patience=5, restore_best_weights=True)\n    \n# Обратный вызов, который передает результаты эпохи в файл CSV.\n# csv_logger = CSVLogger('training.log')\n# csv_logger = [csv_logger]","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:20:06.621382Z","iopub.execute_input":"2022-01-24T22:20:06.621613Z","iopub.status.idle":"2022-01-24T22:20:06.627463Z","shell.execute_reply.started":"2022-01-24T22:20:06.621580Z","shell.execute_reply":"2022-01-24T22:20:06.626681Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Обучаем\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n        # callbacks=csv_logger\n        # callbacks = callbacks_stop\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:20:06.628571Z","iopub.execute_input":"2022-01-24T22:20:06.629563Z","iopub.status.idle":"2022-01-24T22:40:52.238015Z","shell.execute_reply.started":"2022-01-24T22:20:06.629505Z","shell.execute_reply":"2022-01-24T22:40:52.237164Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"#### → Рекомендация. Попробуйте применить transfer learning с fine-tuning.","metadata":{}},{"cell_type":"code","source":"# Сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model):\nmodel.save('../working/model_last.hdf5')\nmodel.load_weights('best_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:40:52.239902Z","iopub.execute_input":"2022-01-24T22:40:52.240247Z","iopub.status.idle":"2022-01-24T22:40:53.291043Z","shell.execute_reply.started":"2022-01-24T22:40:52.240207Z","shell.execute_reply":"2022-01-24T22:40:53.290195Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:40:53.292570Z","iopub.execute_input":"2022-01-24T22:40:53.292813Z","iopub.status.idle":"2022-01-24T22:41:35.068448Z","shell.execute_reply.started":"2022-01-24T22:40:53.292777Z","shell.execute_reply":"2022-01-24T22:41:35.067479Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"---\nИзменение количества эпох на значение 10 с применением callback keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True) остановило обучение на 7 эпохе и не сильно повлияло на результат, зато процесс обучения увеличился.\n> В итоге точность нашей модели составила 93 %. Даное зачение является выше чем baseline и учитывая, что классов десять, является хорошим результатом. Но можно больше.\n---","metadata":{}},{"cell_type":"code","source":"# Посмотрим на графики обучения:\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc)) \n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:41:35.070177Z","iopub.execute_input":"2022-01-24T22:41:35.070445Z","iopub.status.idle":"2022-01-24T22:41:35.583436Z","shell.execute_reply.started":"2022-01-24T22:41:35.070407Z","shell.execute_reply":"2022-01-24T22:41:35.582388Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Предсказание на тестовых данных","metadata":{}},{"cell_type":"code","source":"test_sub_generator.samples","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:41:35.585206Z","iopub.execute_input":"2022-01-24T22:41:35.585636Z","iopub.status.idle":"2022-01-24T22:41:35.595137Z","shell.execute_reply.started":"2022-01-24T22:41:35.585576Z","shell.execute_reply":"2022-01-24T22:41:35.593359Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:41:35.598156Z","iopub.execute_input":"2022-01-24T22:41:35.600050Z","iopub.status.idle":"2022-01-24T22:42:12.951823Z","shell.execute_reply.started":"2022-01-24T22:41:35.600001Z","shell.execute_reply":"2022-01-24T22:42:12.951135Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:42:12.953030Z","iopub.execute_input":"2022-01-24T22:42:12.953379Z","iopub.status.idle":"2022-01-24T22:42:12.981360Z","shell.execute_reply.started":"2022-01-24T22:42:12.953338Z","shell.execute_reply":"2022-01-24T22:42:12.980642Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:42:12.982658Z","iopub.execute_input":"2022-01-24T22:42:12.983061Z","iopub.status.idle":"2022-01-24T22:42:12.994486Z","shell.execute_reply.started":"2022-01-24T22:42:12.983025Z","shell.execute_reply":"2022-01-24T22:42:12.993731Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Test Time Augmentation (TTA)","metadata":{}},{"cell_type":"code","source":"# tta_steps = 10\n# predictions = []\n\n# for i in tqdm(range(tta_steps)):\n#     preds = model.predict_generator(train_datagen.flow(x_val, batch_size=bs, shuffle=False), steps = len(x_val)/bs)\n#     predictions.append(preds)\n\n# pred = np.mean(predictions, axis=0)\n\n# np.mean(np.equal(np.argmax(y_val, axis=-1), np.argmax(pred, axis=-1)))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:42:12.995722Z","iopub.execute_input":"2022-01-24T22:42:12.996420Z","iopub.status.idle":"2022-01-24T22:42:13.000479Z","shell.execute_reply.started":"2022-01-24T22:42:12.996383Z","shell.execute_reply":"2022-01-24T22:42:12.999324Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# <a name=\"Прочее\"></a> Прочее","metadata":{}},{"cell_type":"markdown","source":"## **Предобученная сверточная нейронная сеть Inception-ResNet-v2**:","metadata":{}},{"cell_type":"code","source":"base_model_2 = InceptionResNetV2(weights='imagenet',include_top=False, input_shape = input_shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:42:13.001793Z","iopub.execute_input":"2022-01-24T22:42:13.002707Z","iopub.status.idle":"2022-01-24T22:42:19.929606Z","shell.execute_reply.started":"2022-01-24T22:42:13.002669Z","shell.execute_reply":"2022-01-24T22:42:19.928893Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"base_model_2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:42:19.930679Z","iopub.execute_input":"2022-01-24T22:42:19.931026Z","iopub.status.idle":"2022-01-24T22:42:20.272667Z","shell.execute_reply.started":"2022-01-24T22:42:19.930995Z","shell.execute_reply":"2022-01-24T22:42:20.271875Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Устанавливаем новую «голову» (head):\nx = base_model_2.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.25)(x)\n# and a logistic layer -- let's say we have 10 classes\npredictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n# this is the model we will train\nmodel_2 = Model(inputs=base_model_2.input, outputs=predictions)\nmodel_2.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(learning_rate=LR), metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:42:20.274103Z","iopub.execute_input":"2022-01-24T22:42:20.274376Z","iopub.status.idle":"2022-01-24T22:42:20.359955Z","shell.execute_reply.started":"2022-01-24T22:42:20.274341Z","shell.execute_reply":"2022-01-24T22:42:20.359249Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"model_2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:42:20.361058Z","iopub.execute_input":"2022-01-24T22:42:20.361308Z","iopub.status.idle":"2022-01-24T22:42:20.691923Z","shell.execute_reply.started":"2022-01-24T22:42:20.361275Z","shell.execute_reply":"2022-01-24T22:42:20.691236Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Обучение модели\n\n# Добавим ModelCheckpoint. Эта функция позволяет сохранять прогресс обучения модели, чтобы в нужный момент можно было его подгрузить\n# и дообучить модель:\ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\ncallbacks_list = [checkpoint]\n\ncallbacks_stop = EarlyStopping(patience=5, restore_best_weights=True)\n    \n# Обратный вызов, который передает результаты эпохи в файл CSV.\n# csv_logger = CSVLogger('training.log')\n# csv_logger = [csv_logger]","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:42:20.693398Z","iopub.execute_input":"2022-01-24T22:42:20.693645Z","iopub.status.idle":"2022-01-24T22:42:20.699061Z","shell.execute_reply.started":"2022-01-24T22:42:20.693611Z","shell.execute_reply":"2022-01-24T22:42:20.698391Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Обучаем\nhistory = model_2.fit(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n        # callbacks=csv_logger\n        # callbacks = callbacks_stop\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:42:20.700367Z","iopub.execute_input":"2022-01-24T22:42:20.700607Z","iopub.status.idle":"2022-01-24T23:04:05.352824Z","shell.execute_reply.started":"2022-01-24T22:42:20.700575Z","shell.execute_reply":"2022-01-24T23:04:05.352061Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model):\nmodel_2.save('../working/model_last.hdf5')\nmodel_2.load_weights('best_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:04:05.354511Z","iopub.execute_input":"2022-01-24T23:04:05.354777Z","iopub.status.idle":"2022-01-24T23:04:09.486607Z","shell.execute_reply.started":"2022-01-24T23:04:05.354742Z","shell.execute_reply":"2022-01-24T23:04:09.485827Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"scores = model_2.evaluate(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:04:09.487964Z","iopub.execute_input":"2022-01-24T23:04:09.488226Z","iopub.status.idle":"2022-01-24T23:04:40.706681Z","shell.execute_reply.started":"2022-01-24T23:04:09.488193Z","shell.execute_reply":"2022-01-24T23:04:40.705849Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Посмотрим на графики обучения:\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc)) \n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:04:40.707955Z","iopub.execute_input":"2022-01-24T23:04:40.708638Z","iopub.status.idle":"2022-01-24T23:04:41.100655Z","shell.execute_reply.started":"2022-01-24T23:04:40.708598Z","shell.execute_reply":"2022-01-24T23:04:41.099969Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## **Предобученная нейронная сеть EfficientNetB2**:","metadata":{}},{"cell_type":"code","source":"base_model_3 = EfficientNetB2(include_top=False, weights='imagenet', input_tensor=None, \n    pooling=None, classes=1000, classifier_activation='softmax')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:04:41.102030Z","iopub.execute_input":"2022-01-24T23:04:41.102306Z","iopub.status.idle":"2022-01-24T23:04:43.796381Z","shell.execute_reply.started":"2022-01-24T23:04:41.102269Z","shell.execute_reply":"2022-01-24T23:04:43.795644Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Устанавливаем новую «голову» (head):\nx = base_model_3.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.25)(x)\n# and a logistic layer -- let's say we have 10 classes\npredictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n# this is the model we will train\nmodel_3 = Model(inputs=base_model_3.input, outputs=predictions)\nmodel_3.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(learning_rate=LR), metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:04:43.797763Z","iopub.execute_input":"2022-01-24T23:04:43.797996Z","iopub.status.idle":"2022-01-24T23:04:43.849395Z","shell.execute_reply.started":"2022-01-24T23:04:43.797963Z","shell.execute_reply":"2022-01-24T23:04:43.848734Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model_3.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:04:43.850727Z","iopub.execute_input":"2022-01-24T23:04:43.851131Z","iopub.status.idle":"2022-01-24T23:04:43.999800Z","shell.execute_reply.started":"2022-01-24T23:04:43.851082Z","shell.execute_reply":"2022-01-24T23:04:43.996527Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Обучение модели\n\n# Добавим ModelCheckpoint. Эта функция позволяет сохранять прогресс обучения модели, чтобы в нужный момент можно было его подгрузить\n# и дообучить модель:\ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\ncallbacks_list = [checkpoint]\n\ncallbacks_stop = EarlyStopping(patience=5, restore_best_weights=True)\n    \n# Обратный вызов, который передает результаты эпохи в файл CSV.\n# csv_logger = CSVLogger('training.log')\n# csv_logger = [csv_logger]","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:04:44.005241Z","iopub.execute_input":"2022-01-24T23:04:44.005769Z","iopub.status.idle":"2022-01-24T23:04:44.010662Z","shell.execute_reply.started":"2022-01-24T23:04:44.005740Z","shell.execute_reply":"2022-01-24T23:04:44.009957Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Обучаем\nhistory = model_3.fit(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n        # callbacks=csv_logger\n        # callbacks = callbacks_stop\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:04:44.012089Z","iopub.execute_input":"2022-01-24T23:04:44.012515Z","iopub.status.idle":"2022-01-24T23:24:47.655115Z","shell.execute_reply.started":"2022-01-24T23:04:44.012476Z","shell.execute_reply":"2022-01-24T23:24:47.654251Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model):\nmodel_3.save('../working/model_last.hdf5')\nmodel_3.load_weights('best_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:24:47.657466Z","iopub.execute_input":"2022-01-24T23:24:47.657950Z","iopub.status.idle":"2022-01-24T23:24:49.181455Z","shell.execute_reply.started":"2022-01-24T23:24:47.657912Z","shell.execute_reply":"2022-01-24T23:24:49.180701Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"scores = model_3.evaluate(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:24:49.182745Z","iopub.execute_input":"2022-01-24T23:24:49.183005Z","iopub.status.idle":"2022-01-24T23:25:30.856726Z","shell.execute_reply.started":"2022-01-24T23:24:49.182971Z","shell.execute_reply":"2022-01-24T23:25:30.855807Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Посмотрим на графики обучения:\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc)) \n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:25:30.858139Z","iopub.execute_input":"2022-01-24T23:25:30.858483Z","iopub.status.idle":"2022-01-24T23:25:31.298607Z","shell.execute_reply.started":"2022-01-24T23:25:30.858441Z","shell.execute_reply":"2022-01-24T23:25:31.297929Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"## **Последовательная архитектура нейронной сети с примененной BatchNormalization:**","metadata":{}},{"cell_type":"code","source":"base_model_4 = Sequential()\nbase_model_4.add(Dense(224, input_shape=(input_shape)))\nbase_model_4.add(Activation('relu'))\nbase_model_4.add(Conv2D(224, (3, 3)))\nbase_model_4.add(Activation('relu'))\nbase_model_4.add(Dense(64))\nbase_model_4.add(Activation('relu'))\nbase_model_4.add(Dropout(0.5))\nbase_model_4.add(Dense(10))\nbase_model_4.add(Activation('sigmoid'))\nbase_model_4.add(BatchNormalization())","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:25:31.299803Z","iopub.execute_input":"2022-01-24T23:25:31.300515Z","iopub.status.idle":"2022-01-24T23:25:31.383209Z","shell.execute_reply.started":"2022-01-24T23:25:31.300477Z","shell.execute_reply":"2022-01-24T23:25:31.382522Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Устанавливаем новую «голову» (head):\nx = base_model_4.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.25)(x)\n# and a logistic layer -- let's say we have 10 classes\npredictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n# this is the model we will train\nmodel_4 = Model(inputs=base_model_4.input, outputs=predictions)\nmodel_4.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(learning_rate=LR), metrics=[\"accuracy\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_4.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:25:31.726553Z","iopub.status.idle":"2022-01-24T23:25:31.727265Z","shell.execute_reply.started":"2022-01-24T23:25:31.726993Z","shell.execute_reply":"2022-01-24T23:25:31.727018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обучение модели\n\n# Добавим ModelCheckpoint. Эта функция позволяет сохранять прогресс обучения модели, чтобы в нужный момент можно было его подгрузить\n# и дообучить модель:\ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\ncallbacks_list = [checkpoint]\n\ncallbacks_stop = EarlyStopping(patience=5, restore_best_weights=True)\n    \n# Обратный вызов, который передает результаты эпохи в файл CSV.\n# csv_logger = CSVLogger('training.log')\n# csv_logger = [csv_logger]","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:25:31.728678Z","iopub.status.idle":"2022-01-24T23:25:31.729363Z","shell.execute_reply.started":"2022-01-24T23:25:31.729103Z","shell.execute_reply":"2022-01-24T23:25:31.729144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обучаем\nhistory = model_4.fit(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n        # callbacks=csv_logger\n        # callbacks = callbacks_stop\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:25:31.730662Z","iopub.status.idle":"2022-01-24T23:25:31.731336Z","shell.execute_reply.started":"2022-01-24T23:25:31.731076Z","shell.execute_reply":"2022-01-24T23:25:31.731101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model):\nmodel_4.save('../working/model_last.hdf5')\nmodel_4.load_weights('best_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:25:31.732644Z","iopub.status.idle":"2022-01-24T23:25:31.733322Z","shell.execute_reply.started":"2022-01-24T23:25:31.733063Z","shell.execute_reply":"2022-01-24T23:25:31.733087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model_4.evaluate(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:25:31.734585Z","iopub.status.idle":"2022-01-24T23:25:31.735280Z","shell.execute_reply.started":"2022-01-24T23:25:31.735012Z","shell.execute_reply":"2022-01-24T23:25:31.735038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим на графики обучения:\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc)) \n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:25:31.736584Z","iopub.status.idle":"2022-01-24T23:25:31.737276Z","shell.execute_reply.started":"2022-01-24T23:25:31.737009Z","shell.execute_reply":"2022-01-24T23:25:31.737034Z"},"trusted":true},"execution_count":null,"outputs":[]}]}